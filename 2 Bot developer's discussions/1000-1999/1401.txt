--------------------------------------------------
Subject: need some ideas for multilevel maps
--------------------------------------------------
03/19/01 at 22:27:23  Posted by: Clean (botmans@xlat.cjb.net)
--------------------------------------------------
I would like to know some of your ideas on how to handle button pushing in various conditions. Before I continue, here is my design for any bot:

Bots need to remember places where they've been. This is essential to long term memory and increased skill through learned behavior, through learned drone actions (stupid deaths), through seeing other players actions and mimicking, or by testing out unknown conditions and see if benefits outweigh the losses.

Now we shall continue on the multilevel discussion.

First, my thoughts on exploration (bots create their own (or as a collective) dynamic waypoints):

Bots have cone-sight. Bots can see forward. Suppose bots' visibility was poor over 150 feet away, and that it has some free time to explore, they should look left and right to build a general outline of what its surrounding is. Surely humans do the same. We don't pay attention to details, but we do see walls, edges, and generally how long and wide rooms are. We constantly learn new terrain and its features. Now bots should generalize key edges and connect lines between them and call that an unverified wall. If bots have more free time, then they can explore these unverified walls and build an even more detailed wall. Perhaps they found a door in between unverified walls that lead to other rooms, then they build new links for the new unverified walls that should be visited again sometime later, or maybe just randomly--I have my own design for choosing when bots should explore, but I won't go into that here. Bots should also add new points where it should verify when it sees another player standing behind unverified walls. "How is it possible for the player to walk through a solid wall?" bots may think. So they later explore that area.


Secondly, bots have problems with simple things like button pushing.

I'll talk about simple actions for now. A simple action is bumping into doors to make them open, bumping into doors/walls and pushing the *use* key to see if the path in front of bots' cone-sight just got a further line-of-sight (ref. to unverified walls from above). Jumping over objects, tables, boxes, and stairs are all simple actions that every new bot with a 'fresh' brain to try when it is exploring. Having two or three bots helping each other climbing walls and windows make things even more interesting. Minor intelligence like, "That rooftop is too high, but if I jump on that drum and hop on that ledge, then I could possibly jump and get on the roof" allows bots to assimulate their surroundings better. A lot of bots out there today just jump around like they're trying to masterbate an object in front of it that it can't pass through. I'm suggesting that we do improve on the basic skills of exploration. Bots can learn. Some may learn not to try running away or jumping onto tables at the wrong time since their action decreases their rate of survival and at some speific location if frequently. Exploration mode should not be done in attack mode anyways.

The more sophisticated action is pushing a button. How come it sounds so silly? After all, bots just need to wait for a door to open or an elevator to come up or down before getting into it. So, what happens when bots press a platform button. Wow. They seem to get crushed by the platform everytime :) My suggestion is to break away from hardcoded waypoints. They don't really help bots learn new maps. Bots should look around like previously suggested. And they should look up and down too ;) I don't know if Valve included where sound directions come from, but if they did, bots should zone in on objects that make certatin sounds and moving things as well. A platform that looks like 20 inches may end up looking like 50 feet by 10 seconds! Maybe that's a sign to steer away from platform or die. If enemies are near, perhaps bots should see if the other side of the wall won't be where the moving platform is coming down so they'll survive. If not, then getting shot by enemies closing in tends a better chance for survival than getting crushed.

The last action problems are moving platforms and driving jeeps. For the latter, I think it's up to the developer to see if they want bots to be so complex as to drive their comrades to the bomb area because it's faster and safer ;/ Anyway, moving platform is the bigger problem. I don't think any bots are able realize that by pushing a button that a plaform is moving in front, below, or above of the bots and they need to find a way to access the moving platform and correctly time themselves to jump onto the moving platform. Finding moving platforms require some calculation as to the direction the platform is moving and a point on the map tree that is closest to moving platform. I think any AI would be confused by this point. Bots should try their few basic skills like jumping and climbing. And if they've exahusted most or all possible combinations that it knows, it should find another route to the intended destination. This means keep the interest of going onto the platform to travel somewhere that bots haven't been to before on a list of to-do's. At least bots won't seemingly just act like bots. There's appreciation for even primitive and inquisitive minds ;)

Personally I don't believe that any bots that we try to create now are real life forms. They're just illusions of being human if anyone should ask ;) As for the drone-death feature, even bacterias have this in them. It makes them evolve ;)

Okay, I think I've spoken a little too much. This is only a fraction to what I want to explore. If anyone has any better ways for button pushing, please share with the community.

--------------------------------------------------
03/20/01 at 16:14:43  Reply by: Clean (botmans@xlat.cjb.net)
--------------------------------------------------
What in the world are you talking about? I don't need code. I'm seeking for open ideas to solving problems.

--------------------------------------------------
03/23/01 at 05:04:10  Reply by: theimann (tobias.heimann@cl.cam.ac.uk)
--------------------------------------------------
> Minor intelligence like, "That rooftop is too high, but if I jump on that drum and hop on that 
> ledge, then I could possibly jump and get on the roof" allows bots to assimulate their
> surroundings better. 

On this kind of "minor intelligence" people have been working for nearly fifty years now and you want to know the results? Nobody has the slightest clue on how to teach general reasoning like you described it to computers. 
If you want that behaviour for bots you have to code every step exlicitly and that can get pretty complicated if you want to simulate more complex actions. 

> A platform that looks like 20 inches may end up looking like 50 feet by 10 seconds! 

Like the renderer draws it on the screen, yes. Bots don't see anything of that. They have got their waypoints and entity positions, that's it. You could do collision detection for the bot and moving platforms nearby if you want to avoid getting smashed - it's all just a question of the amount of CPU power you are willing to spend on navigation.

Regarding the buttons: Platforms store a pointer to the button that triggers them, so one possibility would be: 1.press button 2.observe where corresponding platform is moving 3.try to get on that platform 4.store path in waypoint graph
Note that only point 3 can cause significant problems to your bot - so take care!

Tobias



--------------------------------------------------
03/23/01 at 06:07:34  Reply by: theimann (tobias.heimann@cl.cam.ac.uk)
--------------------------------------------------
> ideas are simple its the code that u need man

Nope. Actually it's the other way round: If you've got the right ideas, well planned, implementing them in code not only is the easiest but as well the fastest part of the work. Really :-)

Tobias

--------------------------------------------------
03/23/01 at 16:44:59  Reply by: eLiTe (ali@elitegamer.fsnet.co.uk)
--------------------------------------------------
Yeah that's what my dad says. I can think of code to do something really easily but my dad says you should be able to explain it in normal language to prove you can understand it. You may even make it more efficient that way...

--------------------------------------------------
03/23/01 at 20:22:30  Reply by: Clean (botmans@xlat.cjb.net)
--------------------------------------------------
Guess this going nowhere as predicted ;)

In my respect, CPU power is no problem. The time factor of retrieval might be, but this is already written in my thesis on artificial intelligence regarding memory and time. Some of you fail to realize that I do not propose exact human replications of thought. Give the current bevahioral and cognitive science practices, it is not possible. However, I would like to go on a seperate route such that I am taking the concept of the human mind (since it already works) in application that would create perhaps something more beautiful. Since there is a split amongst the opinions of many people that AI would never be itself a true life form, I chose not to compete against debates. Hence, I am seeking at designing an AI that builds itself given very basic schemas and let it grow complex enough that I have not that much time to waste on decoding how it reaches a conclusion. This to me is life. It is a nutshell that we cannot explain in a lifetime. Perhaps some of you may continue arguing I don't care (read http://www.divinegods.net). The ideas I am searching for such as in pushing a button is the way different humans derive their version of how to do it. The general concept is of course needed to be analyzed through a neural network and CPU is not really a problem for me. This Half Life bot gives me a way to begin programming some of my ideas since most of the graphics and objects/entities are handled by the game engine. It really takes off the burden of writing image analysis code and it is currently still being perfected by specialists around the world. Until then, a game engine that breaks down objects already is simply a matter of letting the AI learn from its interaction within the game world. This I think is really nice. As for coding, I don't really need it. I can ask Botman for suggestions since he's already shown his expertise in the Half Life game engine. I could say I'm fairly experienced in most respects of programming so no code really suprises me. Your ideas and inputs if unique enough CAN suprise me ;) I hope this discussion could lead to a better concrete open forum on ways we can extend AI thought process and nothing else. Thank you to everyone!



--------------------------------------------------
03/24/01 at 14:30:24  Reply by: CountFloyd (countfloyd_1999@yahoo.com)
--------------------------------------------------
QUOTE:

Hence, I am seeking at designing an AI that builds itself given very basic schemas and let it grow complex enough that I have not that much time to waste on decoding how it reaches a conclusion. This to me is life. It is a nutshell that we cannot explain in a lifetime.



Your AI design somehow looks to me much like this attempt:
http://www.botepidemic.com/neuralbot

I'm currently reading a book where the author states that human ideas are much like a physical virus. In short this means ideas mutate from each and every person and are best 'injected' when young. I would like to see this theory in some kind of AI. Practically I could think of the Bots having some already proven ideas (read: action patterns) learned for example from human behaviour and then mutating it (either by genetic algos or fuzzy logic) to try something new and different. Is this a suggestion you wanted or am I a complete weirdo ? ;)

--------------------------------------------------
03/24/01 at 15:54:18  Reply by: Clean (botmans@xlat.cjb.net)
--------------------------------------------------
Count, no this is in the direction of what I wanted yes ;) The neural bot works something similar to all current text book examples of learning. And much of the modern theory of how the brain works include about time as a factor of learning. Here's the thing. Before I was formally introduced to cognitive science, my introspection of my own mind gave me insights to how I think possibly the brain works. I was suprised how many key points I've written on my own as a novice to that field turned out to be the modern examples! The one and only thing that all modern examples have not yet covered clearly is what they define by how long ago something was retrieved from the brain. The basis of my theory states that the "recency"/"recentcy" of the piece of schema/script that was accessed is placed above the older short term and longer memories and the speed of retrieval is based on how important/priority or long you care to retrieve some piece of information and how long ago was the information you are looking for since you had last accessed it. Many cognitive pscyhologists speak of cues like as if cues magically would bring about a piece of information if it were good enough. I simply deduced it was a byproduct of the recency effect since one can have the best cue, e.g. some word that reminded a person of an image, but after years later because that word was rarely used again or some related word to the same semantec schema that trying to recall a word to invoke some "feeling" of a picture takes forever or you may simply give up. Perhaps weeks later you suddenly recall a word that you thought you gave up on it. In my theory, the most plausible logic is that you had touched upon a "cue" but due to the proximity of the last time you were trying to recall the word (and so it has become a priority/importance, you kept the word in your mind for a period of time), you incidentally linked the cue to its former schema given a range of predicates to toggle the right path to the schema related. By the last part, in short it means that I can think of the word "dog" as a Doberman Pinscher, but to relate it to calling humans "dogs" means another context. So the connection to an idea can be connected by many nodes to other ideas and concepts, but it is the signals of attributes that dictate the path of "thought." I think we are unique enough, but don't get me wrong for saying that if our minds were translated into a source code, we would see that it functions like a program but it is still affected by other forms of external events that might change the state of the mind (consequently what you will be thinking next).

Oh, I forgot to say, for the bot project you have a very similar example to mine. Given a bot basic principles to begin with it can later modify and extend what it knew prior. When I tried various bot author's code, most were pretty well hardcoded concepts like strifing while shoot and etc. The next thing you see is that bots ran into walls, hahaha. Anyway, since I don't think my actual recency effect to the modern schema theory is going to get recognized any time soon, the next best thing is a script that has basic movements. Firstly, I'll speak of scripts here as basic ideas and movements. We need to give bots some basic ideas on the range of their arms, legs, distance they can walk such as when strafing, walking cautiously, and running. We won't go into much detail as the game engine doesn't allow you  to swing your arms with your hand holding a pistol like Duke Nukem style. Okay so now the bot knows what it can do it should make it easier on you in your code to know when exactly something isn't working like the bot is trying to jump two stories high but it can only jump 2 feet high, hahaha. Now we implent several action scripts to give the illusion of intelligence--intelligence but not quite yet, it's just movements. These movements are like run forward, kneel, aim, and shoot. Run some way, swing back when jumping, shoot enemy in air, and turn around and run to the next goal or hide or what not (cool eh?). This will get some people interested in bots as you are giving people a chance to put some of their Chow Young Fat combo moves by editing a script file for your bot =) Now as for intelligence or simply a mimick of intelligence, the bot can choose (matching to the most similar condition) of the action it must perform. There four modes in which a bot can operate for Counter Strike (or other mods, but I like CS :) and these are: exploration mode, defensive (semi-camping) mode, offensive mode, and playtime mode (random nonbeneficial actions). For each of these modes, you may put as many thinking/condition scripts are you want--thinking/condition scripts are call thinking/condition scripts :) It seems like programming now isn't it? In the thinking/condition script you can list a couple criterias of the choices the bot can make when certain condition arise. Don't worry about your normal navigation, you can keep that. These are conditions where the bot does extra normal user defined actions ;) Let me give you a sample of the things you can dream up:

1. simple intelligence is a conditional thing; when a bot meets more than two enemies, it's thinking/condition script (let's call it TCS) gives the bot a few choices like shoot the one who is ducking, shoot the one that is standing, if all standing or all ducking, shoot the closer one, or shoot the one that we first have our eyes fixated on and keep shooting, be fixated but shart shooting both, and etc. Scripts tailor the server admin's personality so they can come out pretty unique ;)

2. offensive; like some movie character's moves? No problem, under fire and under the right condition, in the TCS execute the appropriate action script and there ya go. Getting shot while performing an action can lead to other TCS conditions to be invoked so the action script can break at any time or otherwise it's pretty lame to have the bot trying do some combo when it means death. Who knows maybe the admin wants to lock that "feature" and create a lasting impression aftter the bots death =) When the bot is getting hurt or teammates surrounding the bot are getting hurt, your bot engine should see if it can activate the defensive scripts or not if the "feature" is user locked (or with high percentage settings of not "moving on").

3. Playtime; when bots aren't in danger they can stab users for fun provided that friendly fire is not turn on. You want to ensure in your script that they don't do this for the entire duration of the game. 3~5 seconds is acceptable, but in the script you may want to set a maximum times per durations otherwise sometimes random numbers like those retrieved from the runtime library repeat a lot and you see the bot just standing there performing a single action for the longest time.

4. exploration, well bots aren't that inquisitive. exploration script i doubt can be a simple text edit by normal users. i think these should be map analysis maps showing hotspots of where to go, or in my previous post above, to write dynamic waypoints to build their own maps and find their own hotspots by their own or by seeing someone there, or by going there following someone.

5. defensive; really like the offensive action figure GI Joek, but you can do some nice things. Many times while playing CS, I am being chased by enemies. I run. They know where I am running. I run into the bendy hallways and stay at the corner. I'm listening for footsteps. I hear footsteps, and it's them. Given the first few milliseconds I'll probably have the highest percentage of shooting and at anyone there as a suprise attack and it works fairly well ;) If it turned out to be a teammate, then oh well. Hope I stop shooting before my instincts kill you =) If enough of these defensive scripts get around, wow, we would have very hard to kill bots that AREN'T just killing you from 100mi. away with a USP.

I do hope I'm attracting a crowd of open minded intellectuals to the bot programming community ;)









--------------------------------------------------
04/10/01 at 06:03:39  Reply by: William (william@botepidemic.com)
--------------------------------------------------
In general, I recommend against combining exploration and advanced reasoning in a single bot, unless you care just about AI.
In practice, bots are either good at exploring the terrain, and doing simple behavior in the presence of an incomplete model of their surroundings, or doing complex behavior using a complete model of their surroundings.
The practical limitations of combining both approaches are in code complexity, and the time required to create advanced AI that is robust and efficient in the presence of lack of information.

(Commercial) game AI typically uses a complete model of their surroundings; customer hate to see the AI suck CPU away to rediscover its surroundings.

The 'button' problem has been tackled successfully since QuakeI, and most often using a complete model of the terrain.
Often, button handling is a simple hack in the original AI. A few game AI's (the original AI for Daikatana, presumably Gladiator for QII, QIIIArena AI) use goal stacks, others (Unreal Tournament, I guess) use custom waypoints and customs states in the FSM, and I've implemented a cumbersome planning system myself.

There's some literature available on this problem in combination with planning:
http://www.ai-center.com/projects/excalibur/documentation/
and notably:
http://www.ai-center.com/projects/excalibur/documentation/model/incomplete/

QUOTE:

designing an AI that builds itself given very basic schemas and let it grow complex enough 




Note, especially in the context of the NeuralBot, that you will not arrive at any AI smarter (or: less stupid) than the inputs and evaluation/feedback function you use.
In the NeuralBot example, the NN ignored terrain, and most likely also team performance. Given these omissions from input and feedback, the AI probably grew more 'complex', but would never grow to take advantage of terrain and teams.
Same for GA's: what isn't represented as part of the genetic string won't be taken into account.

William


