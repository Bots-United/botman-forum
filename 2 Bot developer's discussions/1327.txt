--------------------------------------------------
Subject: The quest for "human-like" bots
--------------------------------------------------
03/06/01 at 18:40:41  Posted by: ExecutionStyle (c_brennan@hotmail.com)
--------------------------------------------------
While reading the book "Frontiers of complexity"[1] last night, I came across the following passage discussing features of a program called <i>Tierra</i>, an artificial life simulator:

QUOTE:

"...in some parts of the Amazon, the physical environment consists of clean white sand, air, falling water, and sunshine.  Embedded in that physical environment is the most complex ecosystem on earth, with hundreds of thousands, possibly millions of organisms.  These do not represent hundreds of thousands of adaptations to the physical environment but hundreds of thousands of adaptations to other organisms: the organisms themselves become the dominant part of the environment, with the physical environment almost fading into insignificance in comparison."




This concept is incredibly deep: the vast wealth of diversity in the Amazon rainforest is based on four things: water, air, sand and sunshine.  

The same concept applies to why humans behave like they do in half-life.  Consider de_dust in Counter-Strike.  It is a very simple level with a few rooms and tunnels, two bomb spots.  Heck, all the walls in the level are orthogonal!  Yet based on this simple physical environment, hundreds of thousands, possibly millions of hours have been spent by countless gamers doing battle with each other. (I know I've put in at least a few hundred ;o)  

The incredibly complex behaviour exhibited by these players doesn't come so much from the placements of walls or bomb spots or in figuring out where the shortest path is to get from A to B, but interactions with the other players in their environment, which can never be fully anticipated.

For a bot to act like a human, it's first focus has to be on reacting to the other entities it meets in a game.  Adequate knowledge of the physical environment is needed, too, but the real complexity, the real "human-like" behaviour comes from anticipating and reacting to the actions of the other players in the game.

I'm reading back over this post and I know it's already pretty long.  Hopefully everyone got this far and gets what I'm talking about.  What we need to do is figure out how we can measure and record bot interactions with other players in such a way that we at least approximate what a human player would record and remember when playing a game like Counter-Strike for the first time.  

(Sorry for the bias to Counter-Strike here ;) but it's the reason I'm even thinking about writing a bot, so [sm]:P[/sm]. hehehe )

So.. do you agree / disagree with my conclusions?  Here's your chance to let everyone know! :o)  

-Carl


[1] <i>Frontiers of complexity - the search for order in a chaotic world</i>.  Peter Coveney and Roger Highfield.

--------------------------------------------------
03/06/01 at 19:36:56  Reply by: bigjesus (holybigjesus@hotmail.com)
--------------------------------------------------
I didn't want to be the first to reply to this but thats because My replies are usualy odd and out of place. Now the only real thing that I have to help me learn how humans play is playing on the net(interacting with other humans) however random things may happen but what is random who made it up? And damn it Wheres the "white sand, air, falling water, and sunshine"?


--------------------------------------------------
03/07/01 at 03:41:58  Reply by: theimann (tobias.heimann@cl.cam.ac.uk)
--------------------------------------------------
You are right. The problem with human players reactions is that they are nearly unpredictable: Given the same situation in a game (seen an enemy at a certain position from a certain point, same weapons etc) the reactions could be very different. That's because human players not only decide on their environment (which is level and yes, more important, other players) but on their current mood as well.
The simplest thing to simulate this would be using a randomizer to decide between different plausible actions, but it isn't that simple I fear. However you could gain a lot analyzing the things that happened before (as you posted in the other thread) and try to make the bots decisions take these into account. I'm not talking about just recording what happened and where other players where spottet, but of translating this info into a more complex thin like "state of mind". Example: If a player has been shot several times at the beginning of the round, he'll behave more careful to be able to enjoy the game longer. If he hasn't seen an enemy for a longer time and then spots one he'll attack more agressively because he has been bored... The quest is to implement this kind of things into your goalfinder. Could be interesting...

Tobias

--------------------------------------------------
03/07/01 at 05:47:18  Reply by: @$3.1415rin (as3.1415rin@gmx.de)
--------------------------------------------------
But AL or in general evolutionary approches converge really slow. And if u want to this, u have to have a so called fitness function. I think esp. in CS it's very difficult have evaluate the skill of one player, cause it's very weapon and team depending. I know there are some approaches fr deathmatch bots, but i don't think that this'll work for games like cs. First u have tis prob with the evaluation, then u'll have problems with time : U need a lot of generations and if one round in cs would be an evaluation period for this fitness function it would take a long time to get better bots. In some 'non-bot' experiments the scientists saw better behavior after 50 generations ... that's impossible for such a game, i think, although u might save this stuff and go on next time.
But as long as we have this problem, that this bot would evolve quite slow, we cannot manage the making the bot 'human-like', i.e. p.ex. changing tactics after having lost, camping, where noone would except an enemy etc..

In my bot I'm using artificial neural networks (5-6-6-5 feedforward BProp)at least for combat. I invented the related training data, while thinking about a lot of possible situations. Then i collected data from real games, categorized it with SOMs and looked for differences between the 'real-game' data and the training data. I think this approach is sometimes useful, although it takes some time and it cannot be processed automatically.

--------------------------------------------------
03/07/01 at 06:17:49  Reply by: Mercenary (adamc_@hotmail.com)
--------------------------------------------------
Thats deep...

--------------------------------------------------
03/07/01 at 06:19:29  Reply by: theimann (tobias.heimann@cl.cam.ac.uk)
--------------------------------------------------
That's not what I meant: You are right, using NNs or GAs for bots to learn from scratch is up to impossible because of the nearly infinite amount of different situations and corresponding actions that can occur within the game. What I thought about is implementing this behaviour explicitly: Using adequate functions you could model the change of inner state of mind sufficiently well and without consuming too much CPU power.

Tobias

--------------------------------------------------
03/07/01 at 11:03:29  Reply by: William (william@botepidemic.com)
--------------------------------------------------
QUOTE:

What we need to do is figure out how we can measure and record bot interactions with other players in such a way that we at least approximate what a human player would record and remember when playing a game like Counter-Strike for the first time.




I don't agree with this position.

On mimicing humans (and I'm going to exagerate):
do we put on feathers and flap our arms if we need to fly? do we grow a tail and distill oxygen from water if we need to stay under water?

Nature can be a great source of inspiration. But it isn't the only source. Any means that will have you produce a challenging AI is valid. Waypoints, the rand() function, cheating, whatever.

Sometimes, it's better that the AI isn't that human. 
For example, I'm currently toying aroud with an Omaha map (for Q2 dday, but HL DoD is quite similar). There's no way I can find 24 friends that volunteer to storm from the landing crafts for 2 hours on a row, while I'm operating a heavy machine gun from a solid bunker, also defended by a few AI buddies :).
(Having AI that is somewhat scriptable is attractive).

btw. I probably posted the URL somewhere else, but there's a really interesting paper on modeling the AI after the human nervous system. The resulting AI is pretty elegant, except for the navigation stuff, which seems unnecessarily inefficient.
See: http://www.gamasutra.com/features/19991110/guy_01.htm
 

William

--------------------------------------------------
03/07/01 at 15:03:52  Reply by: ExecutionStyle (c_brennan@hotmail.com)
--------------------------------------------------
Wow, great replies people!

I want to respond mainly to two points raised: training time and William's conjecture about nature not necessarily being the best guide.

1) Aspirin, I had thought of the problem you brought up, that if fitness was evaluated at the end of a round, then it would take an extremely long time to train bots.  I don't believe this will be the problem it appears to be.  The reason is that I want to judge the fitness of decisions, not the entire entity.  Examples of a decision are which gun to buy, which route to take from the beginning, whether to camp or rush, and how to cross a given room or area.  

The crucial distinction this makes is that decisions can be classed according to the time span they operate in.  Some decisions are split-second (aim for head or body?) and some are almost round-length (gun choice).  Fitness training can be done separately for each decision effect duration class, so for example a bot could be trained to accomplish a difficult jump by trying over and over again, taking very little time for each trial.

This exactly mimics human learning.  We learn quickly to control our player and hit the right keys; it takes us longer to learn strategy.  As a maxim, this would be "first things first".  So as far as training time is concerned, I don't think there's a problem.


2) William, I'll use your examples for my purposes.  You say:

QUOTE:

do we put on feathers and flap our arms if we need to fly? do we grow a tail and distill oxygen from water if we need to stay under water?




The precise mechanism we use to accomplish things our body wasn't designed to do are different than nature's.  But don't forget that we accomplish effectively the same thing.  Airplanes have wings that generate life, the same as a bird's, and SCUBA equipment supplies oxygen to the body the same way a fish's gills do.  

What we're doing is creating a layer between ourselves and the environment to mimic nature's behaviour.  What's I'm proposing to do with bots is the same thing.  

A bot is incapable of remembering the game world like a human does because it doesn't have a human brain, so I'm suggesting a way to design a layer between the game and bot that would allow it to do effectively the same thing: store information about what happened during its interactions with the game world.  

Hope that was clear!

-Carl

--------------------------------------------------
03/07/01 at 15:26:09  Reply by: William (william@botepidemic.com)
--------------------------------------------------
Two comments:
I haven't seen birds that carry nice stewardesses, show a Schwarzenegger movie, fly faster than 900 kph, and have insufficient leg room. That's no longer mimicing nature.

More seriously, many people state that by recording everything, and feed that to a learning mechanism, the AI will pick up every trick.

The problem with that reasoning is that in practice (NN's, GA's), the AI will never learn more than the evaluation function explictly identifies. 
Evaluation functions that take into account everything that happens at 1000+ waypoints in 300 seconds with 20 players and 20 weapons simply are not very feasible.

Have a look at the results obtained with a Q2 NN based bot: http://www.botepidemic.com/neuralbot and you know what I mean.

William

--------------------------------------------------
03/07/01 at 17:45:33  Reply by: tweak3d (Tweak3d@home.com)
--------------------------------------------------
I had an idea a while back but i have no idea on how to set it up. wouldn't it be possible to make a program of some type that watched the movement of every player including there x ,y ,and z variable on a 24/7 dust map for say. with the results some how make a nodeing system that is based off what the logs have seen. for example 8 different people have gotten alot of kills from this spot but 15 people have gotten killed over there ( as in next to the spot a few feet over ) so the most reasonable place for a bot with a higher intellegence would be to go to that spot and camp, or follow the average route of where those players normaly go. but then for the bots with a low intellegence they would follow the routes that the most deaths have been on such as rushing as a CT out of the tunnel on Dust. if this is possible i know it would be very time consuming to play a map for 24 hours but still look at the results. plz give me some feed back on this idea. thanks.

-Justin

--------------------------------------------------
03/07/01 at 18:58:13  Reply by: Mercenary (adamc_@hotmail.com)
--------------------------------------------------
I'm just not quite sure what to say.  I am sure there is no easy way to make bots human.  I have yet to see a bot be more human than bot.  Bots do not incorporate anything "of the moment"  One round I might rush in with guns blazing mowing down anything that moves.  Other rounds I might hang back and provide cover fire and backup.  All bots I have seen (quite a few between HL and Q2) just run around (90% randomly) and shoot full auto at anything not friendly.  The bots need to have human like movement (nothing I've seen is CLOSE) and maybe even choices as to their style and strategy.  What I do every round is diffrent because people always try new things to win, and never go the same way twice (unless it seems to work well)  The bots need this same information in order to make movement and combat decisions.  Maybe they should be able to remember what can work and what won't.  Maybe even add some free styling.  The bots need to be able to react to any given situation and adapt their skills accordingly.  If they keep getting shot at whenever they go way X, maybe they should go way Y that can take them to cover.  Maybe the bot wants to just hang back this round and get money...

I am running out of brain juice...I'll think more later.

--------------------------------------------------
03/08/01 at 04:28:24  Reply by: theimann (tobias.heimann@cl.cam.ac.uk)
--------------------------------------------------
Justin, the observation of players and analyzation of movement is possible and not too hard to implement: I'm using the method you described for HL deathmatch with very good results after only 10 - 20 minutes of playing (on crowded maps) - you don't have to wait for 24 hours. Avoidance of dangerous zones applies to all bots, not only the higher skilled ones - the lower skilled bots get killed often enough, there's no need to make it harder by chosing the most dangerous paths on the map.

Tobias

--------------------------------------------------
03/10/01 at 09:03:47  Reply by: eLiTe (ali@elitegamer.fsnet.co.uk)
--------------------------------------------------
Also since you will know that the bot isn't human it affects your judgement - there may be some humans in the world that would do exactly the same as a bot (not very likely, but still possible)... if you were playing against a server with some humans and some bots, you will not always be able to tell them apart, and I think people are too quick to critiscise bots as being inhuman... people always treat bots as inferior, while if they were playing against humans they would be much more cautious, and so on... fi they do not play as if they are playing against humans, the experience will be different.

I think that most bots actually are too easy - when I was making my bots I wanted the reaction time fair, but then I realised that I could take out bots way too easy, and that humans would be much faster... but then if you increase the reaction speed you will get humans complaining, simply because they feel that they should be superior to the bots, and that they should be able to pick them off without getting hurt... well that is what I think.

--------------------------------------------------
03/10/01 at 23:36:37  Reply by: William (william@botepidemic.com)
--------------------------------------------------
Alistair,

humans don't react that quickly. However, they compensate for that by looking in the "right direction" very often, and by anticipating opponents.

If the AI doesn't know where to look and how to anticipate, you can make them react quicker; that, however, may feel inhuman at times.

William

--------------------------------------------------
03/30/01 at 17:30:07  Reply by: eLiTe (ali@elitegamer.fsnet.co.uk)
--------------------------------------------------
Well in my recent versions of my bots, they do look about accoring to their surroundings/hearing things. If they are coming up to a corner they will strafe round the corner, allowing for more realistic reaction times, not like when you can shoot the bot before it turns the corner (like all CS bots I have played...)

--------------------------------------------------
10/03/01 at 15:37:10  Reply by: laextr (laextr@icqmail.com)
--------------------------------------------------
You could code a few AI points into the game, but the bot decides where it should be, filled with his code to nvigate the area, he could place an point array in each "room" of an area, if he gets more kills in this "room" he would visit it more often. Catch my drift?

Also I don't think it might take that much resources, since it is only an 1 to 500 point array with 2-3 vars.



